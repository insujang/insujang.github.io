


<!DOCTYPE html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="dark"
  data-auto-appearance="true"
><head>
  <meta charset="utf-8" />
  
    <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="rgb(255,255,255)" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Using HuggingFace Transformers &middot; Better Tomorrow with Computer Science</title>
    <meta name="title" content="Using HuggingFace Transformers &middot; Better Tomorrow with Computer Science" />
  
  <meta name="description" content="HF Transformers # HuggingFace (ðŸ¤—) Transformers is a library that enables to easily download the state-of-the-art pretrained models. It is also possible to create and train a model from scratch, after modifying the structure of existing models. Although the library starts from transformer based language models, it became a general community hub and includes other models such as convolution based Resnet.
It can easily be installed via pip 1:
pip install transformers  Most code is borrowed from HuggingFace transformers example codes." />
  
  
  
  <link rel="canonical" href="/2023-04-19/using-huggingface-transformers/" />
  
  
  
  
  
  
  
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.10f51640c62455dc3b2a174cda772e2fee409808982122a17db5129978d396e5a9dec1b325b2c50f7e5f7dbc7d8c62bdcb89f86574ad3d8359acad96fb66e674.css"
    integrity="sha512-EPUWQMYkVdw7KhdM2ncuL&#43;5AmAiYISKhfbUSmXjTluWp3sGzJbLFD35ffbx9jGK9y4n4ZXStPYNZrK2W&#43;2bmdA=="
  />
  
  
  <script type="text/javascript" src="/js/appearance.min.75869c865625ed3d10fe38f2274fa90938094d28b518ee2088f544a29fe6b826626bae550302adcbde61e83ba341bdd928a250d644367723ce01e798033098c5.js" integrity="sha512-dYachlYl7T0Q/jjyJ0&#43;pCTgJTSi1GO4giPVEop/muCZia65VAwKty95h6DujQb3ZKKJQ1kQ2dyPOAeeYAzCYxQ=="></script>
  
  
    
    
  
  
  
    
    <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.6441f8726be4ada95c479c17d34ce0c4f9f734611947904121e8c317136b5a33ca848f1a18723cc0e68b65872b89b5da63293ec3deb8650739be41c518e6f292.js" integrity="sha512-ZEH4cmvkralcR5wX00zgxPn3NGEZR5BBIejDFxNrWjPKhI8aGHI8wOaLZYcribXaYyk&#43;w964ZQc5vkHFGObykg==" data-copy="Copy" data-copied="Copied"></script>
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  <meta property="og:title" content="Using HuggingFace Transformers" />
<meta property="og:description" content="HF Transformers # HuggingFace (ðŸ¤—) Transformers is a library that enables to easily download the state-of-the-art pretrained models. It is also possible to create and train a model from scratch, after modifying the structure of existing models. Although the library starts from transformer based language models, it became a general community hub and includes other models such as convolution based Resnet.
It can easily be installed via pip 1:
pip install transformers  Most code is borrowed from HuggingFace transformers example codes." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2023-04-19/using-huggingface-transformers/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-19T16:10:00-04:00" />
<meta property="article:modified_time" content="2023-04-19T16:10:00-04:00" /><meta property="og:site_name" content="Better Tomorrow with Computer Science" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Using HuggingFace Transformers"/>
<meta name="twitter:description" content="HF Transformers # HuggingFace (ðŸ¤—) Transformers is a library that enables to easily download the state-of-the-art pretrained models. It is also possible to create and train a model from scratch, after modifying the structure of existing models. Although the library starts from transformer based language models, it became a general community hub and includes other models such as convolution based Resnet.
It can easily be installed via pip 1:
pip install transformers  Most code is borrowed from HuggingFace transformers example codes."/>

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Using HuggingFace Transformers",
    "headline": "Using HuggingFace Transformers",
    
    "abstract": "HF Transformers # HuggingFace (ðŸ¤—) Transformers is a library that enables to easily download the state-of-the-art pretrained models. It is also possible to create and train a model from scratch, after modifying the structure of existing models. Although the library starts from transformer based language models, it became a general community hub and includes other models such as convolution based Resnet.\nIt can easily be installed via pip 1:\npip install transformers  Most code is borrowed from HuggingFace transformers example codes.",
    "inLanguage": "en",
    "url" : "\/2023-04-19\/using-huggingface-transformers\/",
    "author" : {
      "@type": "Person",
      "name": "Insu Jang"
    },
    "copyrightYear": "2023",
    "dateCreated": "2023-04-19T16:10:00-04:00",
    "datePublished": "2023-04-19T16:10:00-04:00",
    
    "dateModified": "2023-04-19T16:10:00-04:00",
    
    "keywords": ["dl","python"],
    
    "mainEntityOfPage": "true",
    "wordCount": "1076"
  }]
  </script>


  
  <meta name="author" content="Insu Jang" />
  
    
      <link href="mailto:insujang@umich.edu" rel="me" />
    
      <link href="https://www.linkedin.com/in/insujang" rel="me" />
    
      <link href="https://github.com/insujang" rel="me" />
    
      <link href="https://scholar.google.com/citations?user=U6I8Y98AAAAJ" rel="me" />
    
  
  
  
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,400;0,700;1,400;1,700&display=swap"
    rel="stylesheet">





<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body, {
        delimiters: [
            {left: '$$', right: '$$' , display: true},
            {left: '$', right: '$' , display: false},
            {left: '\\(', right: '\\)', display: false},
            {left: '\\[', right: '\\]', display: true}
        ] });"></script>































































  
  
  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-158110335-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  
  
</head>
<body
    class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400"
          >&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral print:hidden sm:py-10">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >Better Tomorrow with Computer Science</a
  >

      

    </div>
    
    
      <ul class="flex list-none flex-col ltr:text-right rtl:text-left sm:flex-row">
        
          
            <li class="mb-1 sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
              <a
                class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                href="/#about"
                title=""
                >About</a
              >
            </li>
          
            <li class="mb-1 sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
              <a
                class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                href="/research/"
                title=""
                >Research</a
              >
            </li>
          
            <li class="mb-1 sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
              <a
                class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                href="/posts/"
                title=""
                >Posts</a
              >
            </li>
          
        
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex flex-col grow">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
      <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Using HuggingFace Transformers
      </h1>
      <div class="mt-8 mb-12 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
        





  
  



  

  
  
    
  

  

  

  

  

  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2023-04-19 16:10:00 -0400 EDT">Apr 19, 2023</time>
    

    
    
  </div>

  
  
    <div class="my-1 text-xs text-neutral-500 dark:text-neutral-400 ">
      
        
          
            <a
              href="/tags/dl/"
              class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >dl</a
            >
          
            <a
              href="/tags/python/"
              class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >python</a
            >
          
        
      
    </div>
  


      </div>
      
    </header>
    <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
      
        <div class="order-first px-0 lg:order-last lg:max-w-xs ltr:lg:pl-8 rtl:lg:pr-8">
          <div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-10">
            <details open class="mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"
  >
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"
  >
    <nav id="TableOfContents">
  <ul>
    <li><a href="#hf-transformers">HF Transformers</a></li>
    <li><a href="#using-library">Using Library</a>
      <ul>
        <li><a href="#natural-language-processing">Natural Language Processing</a>
          <ul>
            <li><a href="#instatiating-a-model">Instatiating a model</a></li>
            <li><a href="#instantiating-a-dataset">Instantiating a dataset</a></li>
            <li><a href="#loading-a-tokenizer-and-preprocessing">Loading a tokenizer and preprocessing</a></li>
            <li><a href="#train">Train!</a></li>
          </ul>
        </li>
        <li><a href="#image-classification">Image Classification</a>
          <ul>
            <li><a href="#instantiating-a-model">Instantiating a model</a></li>
            <li><a href="#instantiating-a-dataset-1">Instantiating a dataset</a></li>
            <li><a href="#instantiating-an-image-processor-and-preprocessing">Instantiating an Image Processor and preprocessing</a></li>
            <li><a href="#train-1">Train!</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>

          </div>
        </div>
      
      <div class="min-w-0 min-h-0 max-w-prose grow">
        <h1 id="hf-transformers" class="relative group">HF Transformers <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#hf-transformers" aria-label="Anchor">#</a></span></h1>
<p><a href="https://huggingface.co/docs/transformers/index"   target="_blank">HuggingFace (ðŸ¤—) Transformers</a> is a library that enables to easily download the state-of-the-art pretrained models.
It is also possible to create and train a model from scratch, after modifying the structure of existing models.
Although the library starts from <a href="https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html"   target="_blank">transformer</a> based <em>language models</em>, it became a general community hub and includes other models such as convolution based <a href="https://huggingface.co/microsoft/resnet-152"   target="_blank">Resnet</a>.</p>
<p>It can easily be installed via <code>pip</code> <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span>
</code></pre></div><blockquote>
<p>Most code is borrowed from HuggingFace transformers <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch"   target="_blank">example codes</a>.</p>
</blockquote>
<h1 id="using-library" class="relative group">Using Library <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#using-library" aria-label="Anchor">#</a></span></h1>
<p>In this post, I introduce how to create 1. language models, and 2. image classification model (resnet). But HF Transformers is not limited to those models but also supports <a href="https://huggingface.co/docs/transformers/tasks/audio_classification"   target="_blank">audio classification</a> and multimodal (<a href="https://huggingface.co/docs/transformers/tasks/image_captioning"   target="_blank">image captioning</a> or <a href="https://huggingface.co/docs/transformers/tasks/document_question_answering"   target="_blank">document visual question answering</a>).</p>
<p>For the entire post, I use <a href="https://huggingface.co/docs/transformers/model_doc/auto"   target="_blank"><code>AutoClasses</code></a> for easier implementation. The entire examples are implemented in Python using PyTorch.</p>
<p>All model construction starts from instantiating a model configuration, which specifies the model structure (e.g., the number of layers, the number of attentions, etc).
<a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoConfig"   target="_blank"><code>AutoConfig</code></a> is used for this purpose; it automatically downloads well-known model configurations from the <a href="https://huggingface.co/models"   target="_blank">HF model hub</a>.</p>
<blockquote>
<p>It also supports to load local files by getting <code>os.PathLike</code> type of argument, this post only covers downloading the model from the hub by specifying its name.
As it automatically downloads the configs and models and caches them into the local filesystem, we don&rsquo;t have to manually download and manage them.
The first config for gpt2-xl downloads a configuration for <a href="https://huggingface.co/gpt2-xl"   target="_blank">this model</a>, while the second one downloads <a href="https://huggingface.co/microsoft/resnet-152"   target="_blank">this model</a>.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span>

<span class="n">config_gpt2</span>   <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;gpt2-xl&#34;</span><span class="p">)</span>
<span class="n">config_resnet</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;microsoft/resnet-152&#34;</span><span class="p">)</span>
</code></pre></div><p><code>config_gpt2</code> and <code>config_resnet</code> has different class type:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">gpt2</span><span class="o">.</span><span class="n">configuration_gpt2</span><span class="o">.</span><span class="n">GPT2Config</span>       <span class="c1"># config_gpt2</span>
<span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet</span><span class="o">.</span><span class="n">configuration_resnet</span><span class="o">.</span><span class="n">ResNetConfig</span> <span class="c1"># config_resnset</span>
</code></pre></div><p>Both <a href="https://github.com/huggingface/transformers/blob/v4.28.0/src/transformers/models/gpt2/configuration_gpt2.py#L37"   target="_blank"><code>GPT2Config</code></a> and <a href="https://github.com/huggingface/transformers/blob/v4.28.0/src/transformers/models/resnet/configuration_resnet.py#L34"   target="_blank"><code>ResNetConfig</code></a> are subclasses of <a href="https://github.com/huggingface/transformers/blob/v4.28.0/src/transformers/configuration_utils.py#L48"   target="_blank"><code>PretrainedConfig</code></a>, a base class of all <code>Config</code> classes.</p>
<h2 id="natural-language-processing" class="relative group">Natural Language Processing <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#natural-language-processing" aria-label="Anchor">#</a></span></h2>
<h3 id="instatiating-a-model" class="relative group">Instatiating a model <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#instatiating-a-model" aria-label="Anchor">#</a></span></h3>
<p>GPT, BERT, and T5 are very famous examples of natural language processing.</p>
<blockquote>
<p>There are three types of natural language processing models in HF transformers: <code>CausalLM</code>, <code>MaskedLM</code>, and <code>Seq2SeqLM</code>.
HF has two pages to explain <a href="https://huggingface.co/docs/transformers/tasks/language_modeling"   target="_blank">causalLM</a> and <a href="https://huggingface.co/docs/transformers/tasks/masked_language_modeling"   target="_blank">maskedLM</a>, but have no idea what <code>Seq2seqLM</code> is.</p>
</blockquote>
<p>For GPT2, there are two APIs to instantiate a model: <code>AutoModelForPreTraining</code>, and <code>AutoModelForCausalLM</code>:</p>
<blockquote>
<p>Use <code>AutoModel</code> if you do not intend to pretrain the model. The result does not include any pretraining head. For <code>GPT-2</code>, the type of model is <code>GPT2Model</code>, instead of <code>GPT2LMHeadModel</code>.</p>
<p>Use <code>.from_pretrained()</code> API to get pretrained parameters as well.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForPreTraining</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForPreTraining</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config_gpt2</span><span class="p">)</span>
<span class="n">GPT2LMHeadModel</span><span class="p">(</span>
  <span class="p">(</span><span class="n">transformer</span><span class="p">):</span> <span class="n">GPT2Model</span><span class="p">(</span>
    <span class="o">...</span>
  <span class="p">)</span>
<span class="p">)</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForcausalLM</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForcausalLM</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config_gpt2</span><span class="p">)</span>
<span class="n">GPT2LMHeadModel</span><span class="p">(</span>
  <span class="p">(</span><span class="n">transformer</span><span class="p">):</span> <span class="n">GPT2Model</span><span class="p">(</span>
    <span class="o">...</span>
  <span class="p">)</span>
<span class="p">)</span>
</code></pre></div><p>For other models, choose a proper API to instantiate a model. If the API does not support such model, it ruturns the following error:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;t5-base&#34;</span><span class="p">)</span>
<span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="ne">ValueError</span><span class="p">:</span> <span class="n">Unrecognized</span> <span class="n">configuration</span> <span class="k">class</span>  <span class="nc">for</span> <span class="n">this</span> <span class="n">kind</span> <span class="n">of</span> <span class="n">AutoModel</span><span class="p">:</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span>
<span class="n">Model</span> <span class="nb">type</span> <span class="n">should</span> <span class="n">be</span> <span class="n">one</span> <span class="n">of</span> <span class="n">BartConfig</span><span class="p">,</span> <span class="n">BertConfig</span><span class="p">,</span> <span class="n">BertGenerationConfig</span><span class="p">,</span> <span class="n">BigBirdConfig</span><span class="p">,</span> <span class="o">...</span>
</code></pre></div><blockquote>
<p>Find which model is supported by which API <a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForPreTraining"   target="_blank">here</a>.</p>
</blockquote>
<h3 id="instantiating-a-dataset" class="relative group">Instantiating a dataset <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#instantiating-a-dataset" aria-label="Anchor">#</a></span></h3>
<p>HuggingFace also provides <a href="https://huggingface.co/datasets"   target="_blank">various datasets</a>.
For GPT-2, I will use wikitext dataset.</p>
<p>Use <code>datasets</code> package to load a dataset:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">raw_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&#34;wikitext&#34;</span><span class="p">,</span> <span class="s2">&#34;wikitext-2-raw-v1&#34;</span><span class="p">)</span>
</code></pre></div><p>This will load a subset <code>wikitext-2-raw-v1</code> from <a href="https://huggingface.co/datasets/wikitext"   target="_blank">this dataset</a>.</p>
<h3 id="loading-a-tokenizer-and-preprocessing" class="relative group">Loading a tokenizer and preprocessing <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#loading-a-tokenizer-and-preprocessing" aria-label="Anchor">#</a></span></h3>
<p><a href="https://huggingface.co/docs/transformers/main_classes/tokenizer"   target="_blank">A tokenizer</a> is for preparing the inputs for a model.</p>
<p>I could not understand the details but just follows the example code to implement preprocessing
:)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizers</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;gpt2-xl&#34;</span><span class="p">)</span>

<span class="n">column_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">raw_dataset</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
<span class="n">text_column_name</span> <span class="o">=</span> <span class="s2">&#34;text&#34;</span> <span class="k">if</span> <span class="s2">&#34;text&#34;</span> <span class="ow">in</span> <span class="n">column_names</span> <span class="k">else</span> <span class="n">column_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span>

<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">text_column_name</span><span class="p">])</span>

<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">raw_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">tokenize_function</span><span class="p">,</span>
    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">remove_columns</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
    <span class="n">load_from_cache_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">group_texts</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="c1"># Concatenate all texts.</span>
    <span class="n">concatenated_examples</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">examples</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">examples</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">}</span>
    <span class="n">total_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">concatenated_examples</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="c1"># We drop the small remainder, we could add padding if the model supported it instead of this drop, you can</span>
    <span class="c1"># customize this part to your needs.</span>
    <span class="k">if</span> <span class="n">total_length</span> <span class="o">&gt;=</span> <span class="n">max_seq_length</span><span class="p">:</span>
        <span class="n">total_length</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_length</span> <span class="o">//</span> <span class="n">max_seq_length</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_seq_length</span>
    <span class="c1"># Split by chunks of max_len.</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">k</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">t</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">max_seq_length</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_length</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">concatenated_examples</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&#34;labels&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&#34;input_ids&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">result</span>

<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">group_texts</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">load_from_cache_file</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div><h3 id="train" class="relative group">Train! <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#train" aria-label="Anchor">#</a></span></h3>
<blockquote>
<p>Code from <a href="https://github.com/huggingface/transformers/blob/v4.28.0/examples/pytorch/language-modeling/run_clm.py#L528"   target="_blank">here</a>.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">evaluate</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">default_data_collator</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span>

<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&#34;accuracy&#34;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_preds</span><span class="p">):</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_preds</span>
    <span class="c1"># preds have the same shape as the labels, after the argmax(-1) has been calculated</span>
    <span class="c1"># by preprocess_logits_for_metrics but we need to shift the labels</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model_gpt2</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span> <span class="c1"># type: transformers.TrainingArguments</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># If you want to add evaluation, use tokenized_datasets[&#34;validation&#34;]</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">data_collator</span> <span class="o">=</span> <span class="n">default_data_collator</span><span class="p">,</span>
    <span class="n">compute_metrics</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># If you want to add evaluation, use compute_metrics</span>
<span class="p">)</span>
</code></pre></div><h2 id="image-classification" class="relative group">Image Classification <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#image-classification" aria-label="Anchor">#</a></span></h2>
<h3 id="instantiating-a-model" class="relative group">Instantiating a model <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#instantiating-a-model" aria-label="Anchor">#</a></span></h3>
<p>ViT, Resnet are examples of image classification.
Use <code>transformers.AutoModelForImageClassifcation</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModelForImageClassification</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;microsoft/resnet-152&#34;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForImageClassification</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">ResNetForImageClassification</span><span class="p">(</span>
  <span class="p">(</span><span class="n">resnet</span><span class="p">):</span> <span class="n">ResNetModel</span><span class="p">(</span>
    <span class="o">...</span>
  <span class="p">)</span>
<span class="p">)</span>
</code></pre></div><h3 id="instantiating-a-dataset-1" class="relative group">Instantiating a dataset <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#instantiating-a-dataset-1" aria-label="Anchor">#</a></span></h3>
<p>Same with NLP. But use an image set, not text set.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&#34;Maysee/tiny-imagenet&#34;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&#34;image-classification&#34;</span><span class="p">)</span>
</code></pre></div><blockquote>
<p>This dataset does not include any subset, hence omitted.</p>
</blockquote>
<h3 id="instantiating-an-image-processor-and-preprocessing" class="relative group">Instantiating an Image Processor and preprocessing <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#instantiating-an-image-processor-and-preprocessing" aria-label="Anchor">#</a></span></h3>
<p>This is a major difference from training NLP models: instead of using a tokenizer, it should use an image processor.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoImageProcessor</span>
<span class="kn">from</span> <span class="nn">torchvision.transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CenterCrop</span><span class="p">,</span>
    <span class="n">Compose</span><span class="p">,</span>
    <span class="n">Normalize</span><span class="p">,</span>
    <span class="n">RandomHorizontalFlip</span><span class="p">,</span>
    <span class="n">RandomResizedCrop</span><span class="p">,</span>
    <span class="n">Resize</span><span class="p">,</span>
    <span class="n">ToTensor</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">image_processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;microosft/resnet-152&#34;</span><span class="p">)</span>
<span class="n">size</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&#34;shortest_edge&#34;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s2">&#34;shortest_edge&#34;</span> <span class="ow">in</span> <span class="n">image_processor</span><span class="o">.</span><span class="n">size</span>
    <span class="k">else</span> <span class="p">(</span><span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&#34;height&#34;</span><span class="p">],</span> <span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&#34;width&#34;</span><span class="p">])</span>
<span class="p">)</span>

<span class="n">normalize</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="n">image_processor</span><span class="o">.</span><span class="n">image_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">image_processor</span><span class="o">.</span><span class="n">image_std</span>
<span class="p">)</span>
<span class="n">_train_transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="p">),</span>
        <span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">normalize</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">_val_transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="p">),</span>
        <span class="n">CenterCrop</span><span class="p">(</span><span class="n">size</span><span class="p">),</span>
        <span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">normalize</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">train_transforms</span><span class="p">(</span><span class="n">example_batch</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;Apply _train_transforms across a batch.&#34;&#34;&#34;</span>
    <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">_train_transforms</span><span class="p">(</span><span class="n">pil_img</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&#34;RGB&#34;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">pil_img</span> <span class="ow">in</span> <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;image&#34;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">example_batch</span>

<span class="k">def</span> <span class="nf">val_transforms</span><span class="p">(</span><span class="n">example_batch</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;Apply _val_transforms across a batch.&#34;&#34;&#34;</span>
    <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">_val_transforms</span><span class="p">(</span><span class="n">pil_img</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&#34;RGB&#34;</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">pil_img</span> <span class="ow">in</span> <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;image&#34;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">example_batch</span>

<span class="n">dataset</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">train_transforms</span><span class="p">)</span>
<span class="n">dataset</span><span class="p">[</span><span class="s2">&#34;validation&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">val_transforms</span><span class="p">)</span>
</code></pre></div><h3 id="train-1" class="relative group">Train! <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#train-1" aria-label="Anchor">#</a></span></h3>
<p>Use different tokenizer, data collator, compute_metrics to make it work:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
        <span class="n">predictions</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">references</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">label_ids</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">pixel_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">example</span><span class="p">[</span><span class="s2">&#34;labels&#34;</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">:</span> <span class="n">pixel_values</span><span class="p">,</span> <span class="s2">&#34;labels&#34;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">training_args</span><span class="p">,</span> <span class="c1"># type: transformers.TrainingArguments,</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">],</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># use dataset[&#34;validation&#34;] if want to evaluate</span>
    <span class="n">compute_metrics</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">,</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">image_processor</span><span class="p">,</span> <span class="c1"># Now we use image processor for tokenizer input</span>
    <span class="n">data_collator</span> <span class="o">=</span> <span class="n">collate_fn</span><span class="p">,</span>  <span class="c1"># Don&#39;t use default data collator here</span>
<span class="p">)</span>
</code></pre></div><section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://huggingface.co/docs/transformers/installation"   target="_blank">HuggingFace Transformers: Installation</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

      </div>
    </section>
    <footer class="pt-8 max-w-prose print:hidden">
      
  <div class="flex">
    
      
      
        
        <img
          class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4"
          width="96"
          height="96"
          alt="Insu Jang"
          src="/profile_hufec33d24ce71c5c22cc5620410f7e1d1_126481_192x192_fill_q75_box_smart1.jpg"
        />
      
    
    <div class="place-self-center">
      
        <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
          Author
        </div>
        <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
          Insu Jang
        </div>
      
      
      <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          href="mailto:insujang@umich.edu"
          target="_blank"
          aria-label="Email"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://www.linkedin.com/in/insujang"
          target="_blank"
          aria-label="Linkedin"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/insujang"
          target="_blank"
          aria-label="Github"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>

</a
        >
      
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://scholar.google.com/citations?user=U6I8Y98AAAAJ"
          target="_blank"
          aria-label="Google-Scholar"
          rel="me noopener noreferrer"
          >

  <span class="relative inline-block align-text-bottom icon">
    <!-- Uploaded to: SVG Repo, www.svgrepo.com, Transformed by: SVG Repo Mixer Tools -->
<svg fill="currentColor" width="800px" height="800px" viewBox="0 0 24 24" role="img" xmlns="http://www.w3.org/2000/svg"><title>Google Scholar icon</title><path d="M12 24a7 7 0 1 1 0-14 7 7 0 0 1 0 14zm0-24L0 9.5l4.838 3.94A8 8 0 0 1 12 9a8 8 0 0 1 7.162 4.44L24 9.5z"/></svg>
  </span>

</a
        >
      
    
  </div>

</div>
    </div>
  </div>


      

      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="/2022-08-03/analyzing-parallelization-of-attention/">
              <span
                class="mr-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-2 text-neutral-700 transition-transform group-hover:translate-x-[2px] group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Analyzing Parallelization of Attention</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2022-08-03 14:30:00 -0400 EDT">Aug 3, 2022</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="group flex text-right" href="/2023-04-22/torch-fx-transformation-and-pipeline-parallelism/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Torch FX Transformation and Pipeline Parallelism</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2023-04-22 11:13:00 -0400 EDT">Apr 22, 2023</time>
                  
                </span>
              </span>
              <span
                class="ml-2 text-neutral-700 transition-transform group-hover:translate-x-[2px] group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

        
          <div
            class="pointer-events-none absolute top-[100vh] bottom-0 w-12 ltr:right-0 rtl:left-0"
          >
            <a
              href="#the-top"
              class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
              aria-label="Scroll to top"
              title="Scroll to top"
            >
              &uarr;
            </a>
          </div>
        
      </main><footer class="py-10 print:hidden">
  
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2023
            Insu Jang
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://git.io/hugo-congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    
    
      <div
        class="ltr:mr-14 rtl:ml-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
      >
        <button id="appearance-switcher" type="button">
          <div
            class="flex items-center justify-center w-12 h-12 dark:hidden"
            title="Switch to dark appearance"
          >
            

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


          </div>
          <div
            class="items-center justify-center hidden w-12 h-12 dark:flex"
            title="Switch to light appearance"
          >
            

  <span class="relative inline-block align-text-bottom icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


          </div>
        </button>
      </div>
    
  </div>
  
  
</footer>

    </div>
  </body>
</html>
